{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T01:43:10.516360Z",
     "iopub.status.busy": "2025-06-12T01:43:10.515764Z",
     "iopub.status.idle": "2025-06-12T01:43:10.527908Z",
     "shell.execute_reply": "2025-06-12T01:43:10.526455Z",
     "shell.execute_reply.started": "2025-06-12T01:43:10.516330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import Reader, Dataset, SVD, SlopeOne, accuracy\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:43:10.530092Z",
     "iopub.status.busy": "2025-06-12T01:43:10.529753Z",
     "iopub.status.idle": "2025-06-12T01:44:40.121612Z",
     "shell.execute_reply": "2025-06-12T01:44:40.120393Z",
     "shell.execute_reply.started": "2025-06-12T01:43:10.530059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3715918233.py:24: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies before empty genres filter:  45463\n",
      "Movies after empty genres filter:  43021\n",
      "Movies before empty keywords filter:  44104\n",
      "Movies after empty keywords filter:  31362\n",
      "Number of movie IDs in ratings dataframe: 45115\n",
      "Number of movie IDs in movies dataframe: 30728\n",
      "Number of movie IDs present in ratings but missing from movies: 39481\n",
      "Percentage of missing movies: 87.51%\n",
      "Number of movie IDs present in movies but missing from ratings: 25094\n",
      "Percentage of missing movies: 81.66%\n",
      "New number of rows in ratings after removing invalid movie IDs: 10911543\n"
     ]
    }
   ],
   "source": [
    "def extract_actor_name(cast_list, target_order):\n",
    "    cast_list = list(cast_list)\n",
    "    if isinstance(cast_list, list):\n",
    "        for member in cast_list:\n",
    "            if isinstance(member, dict) and member.get('order') == target_order:\n",
    "                return member.get('name')\n",
    "    return np.nan  \n",
    "\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words\n",
    "\n",
    "\n",
    "credits = pd.read_csv('/kaggle/input/the-movies-dataset/credits.csv')\n",
    "keywords = pd.read_csv('/kaggle/input/the-movies-dataset/keywords.csv')\n",
    "movies = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')\n",
    "ratings = pd.read_csv('/kaggle/input/the-movies-dataset/ratings.csv')\n",
    "\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "\n",
    "movies = movies.drop([19730, 29503, 35587])\n",
    "movies['id'] = movies['id'].astype('int')\n",
    "movies['genres'] = movies['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "print(\"Movies before empty genres filter: \", len(movies))\n",
    "movies = movies[movies['genres'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "print(\"Movies after empty genres filter: \", len(movies))\n",
    "movies['description'] = movies['overview']\n",
    "movies['description'] = movies['description'].fillna('')\n",
    "movies = movies.merge(credits, on='id')\n",
    "movies = movies.merge(keywords, on='id')\n",
    "movies['cast'] = movies['cast'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "#Add top 5 actors\n",
    "for i in range(5):\n",
    "    movies[f'order_{i}'] = movies['cast'].apply(lambda x: extract_actor_name(x, i))\n",
    "\n",
    "columns_take = ['genres', 'id', 'title', 'description', 'cast', 'crew', 'keywords', 'order_0', 'order_1', 'order_2', 'order_3', 'order_4']\n",
    "all_columns = movies.columns\n",
    "columns_drop = [column for column in all_columns if column not in columns_take]\n",
    "movies = movies.drop(columns=columns_drop)\n",
    "\n",
    "#movies['cast'] = movies['cast'].apply(literal_eval)\n",
    "movies['crew'] = movies['crew'].apply(literal_eval)\n",
    "movies['keywords'] = movies['keywords'].apply(literal_eval)\n",
    "\n",
    "movies['director'] = movies['crew'].apply(get_director)\n",
    "movies['cast'] = movies['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "movies['cast'] = movies['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "print(\"Movies before empty keywords filter: \", len(movies))\n",
    "movies = movies[movies['keywords'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "print(\"Movies after empty keywords filter: \", len(movies))\n",
    "movies['cast'] = movies['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "movies['director'] = movies['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "movies['director'] = movies['director'].apply(lambda x: [x,x, x])\n",
    "\n",
    "global s\n",
    "s = movies.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'\n",
    "s = s.value_counts()\n",
    "s = s[s > 1]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(filter_keywords)\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "movies['soup'] = movies['keywords'] + movies['cast'] + movies['director'] + movies['genres']\n",
    "movies['soup'] = movies['soup'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "avg_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
    "avg_ratings.rename(columns={'rating': 'avg_rating'}, inplace=True)\n",
    "movies = movies.merge(avg_ratings, how='left', left_on='id', right_on='movieId')\n",
    "movies.drop(columns=['movieId'], inplace=True)\n",
    "\n",
    "#movies = movies[:500]\n",
    "\n",
    "movie_ids_in_ratings = ratings['movieId'].unique()\n",
    "print(f\"Number of movie IDs in ratings dataframe: {len(movie_ids_in_ratings)}\")\n",
    "movie_ids_in_movies = movies['id'].unique()\n",
    "print(f\"Number of movie IDs in movies dataframe: {len(movie_ids_in_movies)}\")\n",
    "\n",
    "missing_ids_ratings = [movie_id for movie_id in movie_ids_in_ratings \n",
    "                    if movie_id not in movie_ids_in_movies]\n",
    "missing_ids_movies = [movie_id for movie_id in movie_ids_in_movies \n",
    "                    if movie_id not in movie_ids_in_ratings]\n",
    "\n",
    "print(f\"Number of movie IDs present in ratings but missing from movies: {len(missing_ids_ratings)}\")\n",
    "print(f\"Percentage of missing movies: {len(missing_ids_ratings) / len(movie_ids_in_ratings) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Number of movie IDs present in movies but missing from ratings: {len(missing_ids_movies)}\")\n",
    "print(f\"Percentage of missing movies: {len(missing_ids_movies) / len(movie_ids_in_movies) * 100:.2f}%\")\n",
    "# Ensure consistent types\n",
    "movies['id'] = movies['id'].astype(int)\n",
    "ratings['movieId'] = ratings['movieId'].astype(int)\n",
    "\n",
    "valid_movie_ids = set(movies['id'])  # Convert to set for fast lookup\n",
    "\n",
    "ratings = ratings[ratings['movieId'].isin(valid_movie_ids)]\n",
    "movies = movies[movies['id'].isin(ratings['movieId'].unique())]\n",
    "print(f\"New number of rows in ratings after removing invalid movie IDs: {len(ratings)}\")\n",
    "movies = movies.drop_duplicates(subset='id', keep='first')\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_items = ratings['movieId'].nunique()\n",
    "\n",
    "user_mapping = {id: idx for idx, id in enumerate(ratings['userId'].unique())}\n",
    "item_mapping = {id: idx for idx, id in enumerate(ratings['movieId'].unique())}\n",
    "#convert non-sequential user IDs to sequential indices for matrix factorization\n",
    "ratings['userId'] = ratings['userId'].map(user_mapping)\n",
    "ratings['movieId'] = ratings['movieId'].map(item_mapping)\n",
    "movies['id'] = movies['id'].map(item_mapping)\n",
    "movies.drop(columns=['crew', 'cast'], inplace=True)\n",
    "ratings.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:40.123416Z",
     "iopub.status.busy": "2025-06-12T01:44:40.123054Z",
     "iopub.status.idle": "2025-06-12T01:44:40.130414Z",
     "shell.execute_reply": "2025-06-12T01:44:40.129158Z",
     "shell.execute_reply.started": "2025-06-12T01:44:40.123392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genres', 'id', 'title', 'description', 'keywords', 'order_0',\n",
       "       'order_1', 'order_2', 'order_3', 'order_4', 'director', 'soup',\n",
       "       'avg_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:40.134322Z",
     "iopub.status.busy": "2025-06-12T01:44:40.133213Z",
     "iopub.status.idle": "2025-06-12T01:44:40.161886Z",
     "shell.execute_reply": "2025-06-12T01:44:40.160778Z",
     "shell.execute_reply.started": "2025-06-12T01:44:40.134278Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              genre  count\n",
      "7             Drama   2991\n",
      "1            Comedy   1601\n",
      "8          Thriller   1222\n",
      "5            Action    989\n",
      "9           Romance    971\n",
      "6             Crime    791\n",
      "3         Adventure    629\n",
      "13           Horror    607\n",
      "10  Science Fiction    524\n",
      "11          Mystery    414\n",
      "4           Fantasy    401\n",
      "16      Documentary    309\n",
      "2            Family    304\n",
      "14          History    262\n",
      "12            Music    204\n",
      "15              War    188\n",
      "17          Western    167\n",
      "0         Animation    157\n",
      "18          Foreign    145\n",
      "19         TV Movie     56\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_genres = movies['genres'].explode()  \n",
    "genre_counts = Counter(all_genres)\n",
    "genre_counts_df = pd.DataFrame(genre_counts.items(), columns=['genre', 'count']).sort_values(by='count', ascending=False)\n",
    "\n",
    "print(genre_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:40.163356Z",
     "iopub.status.busy": "2025-06-12T01:44:40.162991Z",
     "iopub.status.idle": "2025-06-12T01:44:40.179790Z",
     "shell.execute_reply": "2025-06-12T01:44:40.178688Z",
     "shell.execute_reply.started": "2025-06-12T01:44:40.163333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10911543"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:40.181549Z",
     "iopub.status.busy": "2025-06-12T01:44:40.181184Z",
     "iopub.status.idle": "2025-06-12T01:44:40.212858Z",
     "shell.execute_reply": "2025-06-12T01:44:40.211939Z",
     "shell.execute_reply.started": "2025-06-12T01:44:40.181515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5633\n",
      "5634\n",
      "5633\n"
     ]
    }
   ],
   "source": [
    "print(ratings['movieId'].max())\n",
    "print(len(movies))\n",
    "print(movies['id'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:40.214209Z",
     "iopub.status.busy": "2025-06-12T01:44:40.213949Z",
     "iopub.status.idle": "2025-06-12T01:44:41.378454Z",
     "shell.execute_reply": "2025-06-12T01:44:41.377603Z",
     "shell.execute_reply.started": "2025-06-12T01:44:40.214189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rating_counts = ratings['movieId'].value_counts()\n",
    "popular_movie_ids = rating_counts[rating_counts > 100].index\n",
    "\n",
    "# Step 3: Filter ratings and movies DataFrames\n",
    "filtered_ratings = ratings[ratings['movieId'].isin(popular_movie_ids)].copy()\n",
    "filtered_movies = movies[movies['id'].isin(popular_movie_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.379832Z",
     "iopub.status.busy": "2025-06-12T01:44:41.379569Z",
     "iopub.status.idle": "2025-06-12T01:44:41.385913Z",
     "shell.execute_reply": "2025-06-12T01:44:41.384905Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.379808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.387186Z",
     "iopub.status.busy": "2025-06-12T01:44:41.386910Z",
     "iopub.status.idle": "2025-06-12T01:44:41.405992Z",
     "shell.execute_reply": "2025-06-12T01:44:41.404814Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.387162Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreader = Reader(rating_scale=(0.5, 5))\\ndata = Dataset.load_from_df(filtered_ratings[[\\'userId\\', \\'movieId\\', \\'rating\\']], reader)\\n\\n# Define hyperparameter grid\\nsim_options = {\\n    \"n_factors\": [x * 50 for x in range(2,6)],\\n    \"n_epochs\": [x * 10 for x in range(4, 7)],\\n    \"lr_all\": [x / 50 for x in range(1,3)],\\n    \"reg_all\": [0.01, 0.02]\\n\\n}\\n#param_grid = {\"sim_options\": sim_options}\\n\\nsplit = 5\\ngs = GridSearchCV(SVD, sim_options,\\n                   measures=[\\'rmse\\', \\'mae\\'], cv=split, \\n                   n_jobs=6, refit=False)\\ngs.fit(data)\\n\\ndef print_results_table(gs_results, param_name):\\n    print(f\"\\nResults for \\'{param_name}\\':\")\\n    results_df = pd.DataFrame(gs_results)\\n\\n    # Filter columns to only include \\'mean_test_rmse\\', \\'mean_test_mae\\' and the parameter\\n    param_col = f\\'param_{param_name}\\'\\n    relevant_columns = [param_col, \\'mean_test_rmse\\', \\'mean_test_mae\\']\\n    filtered_results = results_df[relevant_columns]\\n\\n    # Group by the parameter and calculate the mean of RMSE and MAE\\n    # This is crucial because gs.cv_results contains all combinations,\\n    # so we need to average across other parameters for a clean view of one.\\n    grouped_results = filtered_results.groupby(param_col).agg(\\n        Avg_RMSE=(\\'mean_test_rmse\\', \\'mean\\'),\\n        Avg_MAE=(\\'mean_test_mae\\', \\'mean\\')\\n    ).reset_index()\\n\\n    # Rename the parameter column for cleaner output\\n    grouped_results = grouped_results.rename(columns={param_col: param_name})\\n\\n    # Sort by the parameter for consistent output\\n    grouped_results = grouped_results.sort_values(by=param_name)\\n\\n    # Format the numerical columns to 3 decimal places\\n    grouped_results[\\'Avg_RMSE\\'] = grouped_results[\\'Avg_RMSE\\'].map(\\'{:.3f}\\'.format)\\n    grouped_results[\\'Avg_MAE\\'] = grouped_results[\\'Avg_MAE\\'].map(\\'{:.3f}\\'.format)\\n\\n    print(grouped_results.to_markdown(index=False))\\n\\n\\n# Print tables for each hyperparameter\\nfor param in sim_options.keys():\\n    print_results_table(gs.cv_results, param)\\n\\nprint(\"\\n--- Best Scores and Parameters ---\")\\nprint(f\"Best RMSE: {gs.best_score[\\'rmse\\']:.3f}\")\\nprint(f\"Best parameters for RMSE: {gs.best_params[\\'rmse\\']}\")\\nprint(f\"Best MAE: {gs.best_score[\\'mae\\']:.3f}\")\\nprint(f\"Best parameters for MAE: {gs.best_params[\\'mae\\']}\")\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(filtered_ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "sim_options = {\n",
    "    \"n_factors\": [x * 50 for x in range(2,6)],\n",
    "    \"n_epochs\": [x * 10 for x in range(4, 7)],\n",
    "    \"lr_all\": [x / 50 for x in range(1,3)],\n",
    "    \"reg_all\": [0.01, 0.02]\n",
    "\n",
    "}\n",
    "#param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "split = 5\n",
    "gs = GridSearchCV(SVD, sim_options,\n",
    "                   measures=['rmse', 'mae'], cv=split, \n",
    "                   n_jobs=6, refit=False)\n",
    "gs.fit(data)\n",
    "\n",
    "def print_results_table(gs_results, param_name):\n",
    "    print(f\"\\nResults for '{param_name}':\")\n",
    "    results_df = pd.DataFrame(gs_results)\n",
    "\n",
    "    # Filter columns to only include 'mean_test_rmse', 'mean_test_mae' and the parameter\n",
    "    param_col = f'param_{param_name}'\n",
    "    relevant_columns = [param_col, 'mean_test_rmse', 'mean_test_mae']\n",
    "    filtered_results = results_df[relevant_columns]\n",
    "\n",
    "    # Group by the parameter and calculate the mean of RMSE and MAE\n",
    "    # This is crucial because gs.cv_results contains all combinations,\n",
    "    # so we need to average across other parameters for a clean view of one.\n",
    "    grouped_results = filtered_results.groupby(param_col).agg(\n",
    "        Avg_RMSE=('mean_test_rmse', 'mean'),\n",
    "        Avg_MAE=('mean_test_mae', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Rename the parameter column for cleaner output\n",
    "    grouped_results = grouped_results.rename(columns={param_col: param_name})\n",
    "\n",
    "    # Sort by the parameter for consistent output\n",
    "    grouped_results = grouped_results.sort_values(by=param_name)\n",
    "\n",
    "    # Format the numerical columns to 3 decimal places\n",
    "    grouped_results['Avg_RMSE'] = grouped_results['Avg_RMSE'].map('{:.3f}'.format)\n",
    "    grouped_results['Avg_MAE'] = grouped_results['Avg_MAE'].map('{:.3f}'.format)\n",
    "\n",
    "    print(grouped_results.to_markdown(index=False))\n",
    "\n",
    "\n",
    "# Print tables for each hyperparameter\n",
    "for param in sim_options.keys():\n",
    "    print_results_table(gs.cv_results, param)\n",
    "\n",
    "print(\"\\n--- Best Scores and Parameters ---\")\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']:.3f}\")\n",
    "print(f\"Best parameters for RMSE: {gs.best_params['rmse']}\")\n",
    "print(f\"Best MAE: {gs.best_score['mae']:.3f}\")\n",
    "print(f\"Best parameters for MAE: {gs.best_params['mae']}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset, SVD, SlopeOne, accuracy\n",
    "import time\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(filtered_ratings[['userId', 'movieId', 'rating']], reader)\n",
    "#best_model = SVD(n_factors = 200, n_epochs = 30, lr_all = 0.02, reg_all = 0.02)\n",
    "best_model = pickle.load(open('/kaggle/input/mf/scikitlearn/default/1/matrix_fac.pickle', \"rb\"))\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "#best_model.fit(trainset)\n",
    "predictions = best_model.test(testset)\n",
    "def round_to_half(x):\n",
    "    return round(x * 2) / 2\n",
    "\n",
    "rounded_predictions = [\n",
    "    pred._replace(est=np.clip(round_to_half(pred.est), 0.5, 5.0))\n",
    "    for pred in predictions\n",
    "]\n",
    "print(\"MSE: \", predictions)\n",
    "print(\"Rounded MSE: \",accuracy.mse(rounded_predictions))\n",
    "\n",
    "pickle.dump(best_model, open('matrix_fac.pickle', \"wb\"))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "print(test.predict(i, j, r_ui= filtered_ratings[(filtered_ratings.userId==i)&(filtered_ratings.movieId==j)]['rating'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.449503Z",
     "iopub.status.busy": "2025-06-12T01:44:41.449155Z",
     "iopub.status.idle": "2025-06-12T01:44:41.934833Z",
     "shell.execute_reply": "2025-06-12T01:44:41.933591Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.449475Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating actor average ratings...\n",
      "Total unique actors: 14814\n",
      "Overall average rating across all actors: 3.134\n",
      "Substituting actor average ratings in order columns...\n",
      "Substitution completed!\n"
     ]
    }
   ],
   "source": [
    "def calculate_actor_average_ratings(df):\n",
    "    movies_df = df.copy()\n",
    "    actor_ratings = {}\n",
    "    order_columns = ['order_0', 'order_1', 'order_2', 'order_3', 'order_4']\n",
    "    \n",
    "    print(\"Calculating actor average ratings...\")\n",
    "    \n",
    "    for idx, row in movies_df.iterrows():\n",
    "        movie_rating = row['avg_rating']\n",
    "        if pd.isna(movie_rating):\n",
    "            continue\n",
    "            \n",
    "        for col in order_columns:\n",
    "            actor = row[col]\n",
    "            if pd.isna(actor) or actor == '':\n",
    "                continue\n",
    "            if actor not in actor_ratings:\n",
    "                actor_ratings[actor] = {'total_rating': 0, 'movie_count': 0}\n",
    "            \n",
    "            # Add rating and increment count\n",
    "            actor_ratings[actor]['total_rating'] += movie_rating\n",
    "            actor_ratings[actor]['movie_count'] += 1\n",
    "    \n",
    "    actor_avg_ratings = {}\n",
    "    for actor, data in actor_ratings.items():\n",
    "        actor_avg_ratings[actor] = data['total_rating'] / data['movie_count']\n",
    "    \n",
    "    all_actor_ratings = list(actor_avg_ratings.values())\n",
    "    overall_avg_rating = np.mean(all_actor_ratings) if all_actor_ratings else 0\n",
    "    \n",
    "    print(f\"Total unique actors: {len(actor_avg_ratings)}\")\n",
    "    print(f\"Overall average rating across all actors: {overall_avg_rating:.3f}\")\n",
    "    \n",
    "    print(\"Substituting actor average ratings in order columns...\")\n",
    "    \n",
    "    for col in order_columns:\n",
    "        movies_df[col] = movies_df[col].map(actor_avg_ratings)\n",
    "        movies_df[col] = movies_df[col].fillna(overall_avg_rating)\n",
    "    \n",
    "    print(\"Substitution completed!\")\n",
    "    \n",
    "    return movies_df, actor_avg_ratings, overall_avg_rating\n",
    "\n",
    "# Example usage and verification function\n",
    "def verify_results(original_df, modified_df, actor_avg_ratings, overall_avg_rating):\n",
    "    \"\"\"\n",
    "    Verify the results and show some statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VERIFICATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    order_columns = ['order_0', 'order_1', 'order_2', 'order_3', 'order_4']\n",
    "    \n",
    "    # Show sample of actor average ratings\n",
    "    print(f\"\\nSample of actor average ratings:\")\n",
    "    sample_actors = list(actor_avg_ratings.items())[:10]\n",
    "    for actor, rating in sample_actors:\n",
    "        print(f\"  {actor}: {rating:.3f}\")\n",
    "    \n",
    "    # Show statistics for order columns\n",
    "    print(f\"\\nOrder columns statistics (after substitution):\")\n",
    "    for col in order_columns:\n",
    "        non_null_count = modified_df[col].notna().sum()\n",
    "        avg_rating = modified_df[col].mean()\n",
    "        print(f\"  {col}: {non_null_count} non-null values, avg rating: {avg_rating:.3f}\")\n",
    "    \n",
    "    # Show before/after comparison for first few rows\n",
    "    print(f\"\\nBefore/After comparison (first 5 rows):\")\n",
    "    print(\"Original order columns:\")\n",
    "    print(original_df[order_columns].head())\n",
    "    print(\"\\nModified order columns (with average ratings):\")\n",
    "    print(modified_df[order_columns].head())\n",
    "\n",
    "modified_df, actor_ratings, overall_avg = calculate_actor_average_ratings(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.936148Z",
     "iopub.status.busy": "2025-06-12T01:44:41.935833Z",
     "iopub.status.idle": "2025-06-12T01:44:41.966616Z",
     "shell.execute_reply": "2025-06-12T01:44:41.965757Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.936124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_clean = modified_df['genres'].fillna('').apply(lambda x: x if isinstance(x, list) else [])\n",
    "genres_encoded = mlb.fit_transform(genres_clean)\n",
    "genres_df = pd.DataFrame(genres_encoded, \n",
    "                        columns=[f'{genre}' for genre in mlb.classes_],\n",
    "                        index=modified_df.index)\n",
    "modified_df = pd.concat([modified_df, genres_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.967974Z",
     "iopub.status.busy": "2025-06-12T01:44:41.967714Z",
     "iopub.status.idle": "2025-06-12T01:44:41.975893Z",
     "shell.execute_reply": "2025-06-12T01:44:41.974860Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.967953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modified_df.drop(columns=['description', 'title', 'director', 'soup','keywords'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:41.977614Z",
     "iopub.status.busy": "2025-06-12T01:44:41.977211Z",
     "iopub.status.idle": "2025-06-12T01:44:42.009810Z",
     "shell.execute_reply": "2025-06-12T01:44:42.008758Z",
     "shell.execute_reply.started": "2025-06-12T01:44:41.977582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>order_0</th>\n",
       "      <th>order_1</th>\n",
       "      <th>order_2</th>\n",
       "      <th>order_3</th>\n",
       "      <th>order_4</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>History</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>TV Movie</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>2710</td>\n",
       "      <td>3.218628</td>\n",
       "      <td>3.571914</td>\n",
       "      <td>3.638176</td>\n",
       "      <td>3.216323</td>\n",
       "      <td>3.205199</td>\n",
       "      <td>3.598930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>3738</td>\n",
       "      <td>3.168370</td>\n",
       "      <td>3.760163</td>\n",
       "      <td>3.090169</td>\n",
       "      <td>3.760163</td>\n",
       "      <td>3.817607</td>\n",
       "      <td>3.760163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "      <td>1221</td>\n",
       "      <td>3.385523</td>\n",
       "      <td>3.363182</td>\n",
       "      <td>3.202128</td>\n",
       "      <td>3.126661</td>\n",
       "      <td>3.098204</td>\n",
       "      <td>3.905544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Adventure, Action, Thriller]</td>\n",
       "      <td>2006</td>\n",
       "      <td>3.337938</td>\n",
       "      <td>3.345751</td>\n",
       "      <td>3.013024</td>\n",
       "      <td>2.893813</td>\n",
       "      <td>3.006704</td>\n",
       "      <td>2.740334</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Action, Adventure]</td>\n",
       "      <td>302</td>\n",
       "      <td>3.645755</td>\n",
       "      <td>3.158339</td>\n",
       "      <td>2.829485</td>\n",
       "      <td>3.459919</td>\n",
       "      <td>3.710181</td>\n",
       "      <td>3.710181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              genres    id   order_0   order_1   order_2  \\\n",
       "0        [Animation, Comedy, Family]  2710  3.218628  3.571914  3.638176   \n",
       "1       [Adventure, Fantasy, Family]  3738  3.168370  3.760163  3.090169   \n",
       "5   [Action, Crime, Drama, Thriller]  1221  3.385523  3.363182  3.202128   \n",
       "8      [Adventure, Action, Thriller]  2006  3.337938  3.345751  3.013024   \n",
       "13               [Action, Adventure]   302  3.645755  3.158339  2.829485   \n",
       "\n",
       "     order_3   order_4  avg_rating  Action  Adventure  ...  History  Horror  \\\n",
       "0   3.216323  3.205199    3.598930       0          0  ...        0       0   \n",
       "1   3.760163  3.817607    3.760163       0          1  ...        0       0   \n",
       "5   3.126661  3.098204    3.905544       1          0  ...        0       0   \n",
       "8   2.893813  3.006704    2.740334       1          1  ...        0       0   \n",
       "13  3.459919  3.710181    3.710181       1          1  ...        0       0   \n",
       "\n",
       "    Music  Mystery  Romance  Science Fiction  TV Movie  Thriller  War  Western  \n",
       "0       0        0        0                0         0         0    0        0  \n",
       "1       0        0        0                0         0         0    0        0  \n",
       "5       0        0        0                0         0         1    0        0  \n",
       "8       0        0        0                0         0         1    0        0  \n",
       "13      0        0        0                0         0         0    0        0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:44:42.011260Z",
     "iopub.status.busy": "2025-06-12T01:44:42.010907Z",
     "iopub.status.idle": "2025-06-12T01:44:42.027589Z",
     "shell.execute_reply": "2025-06-12T01:44:42.026220Z",
     "shell.execute_reply.started": "2025-06-12T01:44:42.011238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genres', 'id', 'order_0', 'order_1', 'order_2', 'order_3', 'order_4',\n",
       "       'avg_rating', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
       "       'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n",
       "       'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n",
       "       'Thriller', 'War', 'Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T02:18:18.951363Z",
     "iopub.status.busy": "2025-06-12T02:18:18.950947Z",
     "iopub.status.idle": "2025-06-12T02:18:19.408159Z",
     "shell.execute_reply": "2025-06-12T02:18:19.406917Z",
     "shell.execute_reply.started": "2025-06-12T02:18:18.951337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected User ID: 169281\n",
      "\n",
      "Selected Movie for Similarity Search: The Chorus (Movie ID: 773)\n",
      "\n",
      "Top 15 Similar Movies:\n",
      "Zero for Conduct (Similarity: 0.2858)\n",
      "The Chemical Brothers: Don't Think (Similarity: 0.2726)\n",
      "The Duke Is Tops (Similarity: 0.2726)\n",
      "Les Misérables in Concert - The 25th Anniversary (Similarity: 0.2425)\n",
      "Chapiteau-Show (Similarity: 0.2368)\n",
      "The Heat's On (Similarity: 0.2368)\n",
      "Radio Day (Similarity: 0.2368)\n",
      "Five Dances (Similarity: 0.2299)\n",
      "Diabolique (Similarity: 0.2165)\n",
      "The Hessen Affair (Similarity: 0.2101)\n",
      "Mädchen in Uniform (Similarity: 0.2099)\n",
      "Jesus Christ Superstar (Similarity: 0.2098)\n",
      "The Age of Love (Similarity: 0.2025)\n",
      "Still Bill (Similarity: 0.1843)\n",
      "Official Rejection (Similarity: 0.1798)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "movies = movies.reset_index(drop=True)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['soup'])\n",
    "\n",
    "min_ratings = 100\n",
    "max_ratings = 150\n",
    "\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "eligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index.tolist()\n",
    "\n",
    "if not eligible_users:\n",
    "    print(\"No users found in this rating interval.\")\n",
    "else:\n",
    "    selected_user = random.choice(eligible_users)\n",
    "    user_ratings = ratings[ratings['userId'] == selected_user]\n",
    "    user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n",
    "\n",
    "    print(f\"\\nSelected User ID: {selected_user}\")\n",
    "\n",
    "    selected_movie = user_movies.sample(1).iloc[0]\n",
    "    selected_movie_id = selected_movie['id']\n",
    "    selected_movie_index = movies[movies['id'] == selected_movie_id].index[0]\n",
    "\n",
    "    print(f\"\\nSelected Movie for Similarity Search: {selected_movie['title']} (Movie ID: {selected_movie_id})\")\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[selected_movie_index], tfidf_matrix).flatten()\n",
    "\n",
    "    similar_indices = cosine_sim.argsort()[::-1]\n",
    "    top_indices = [i for i in similar_indices if i != selected_movie_index][:15]\n",
    "\n",
    "    # Step 10: Print top 10 similar movies\n",
    "    print(\"\\nTop 15 Similar Movies:\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"{movies.iloc[idx]['title']} (Similarity: {cosine_sim[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:47:19.935957Z",
     "iopub.status.busy": "2025-06-12T01:47:19.935560Z",
     "iopub.status.idle": "2025-06-12T02:00:55.083447Z",
     "shell.execute_reply": "2025-06-12T02:00:55.082010Z",
     "shell.execute_reply.started": "2025-06-12T01:47:19.935932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idf matrix shape:  (5634, 5000)\n",
      "\n",
      "Rating Interval: [100, 150)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.9923, MAE: 0.7571\n",
      "Ridge (SGDRegressor) - MSE: 4.2617, MAE: 1.8526\n",
      "\n",
      "Rating Interval: [200, 250)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 1.0463, MAE: 0.7795\n",
      "Ridge (SGDRegressor) - MSE: 2.9519, MAE: 1.4969\n",
      "\n",
      "Rating Interval: [300, 350)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 1.1101, MAE: 0.8042\n",
      "Ridge (SGDRegressor) - MSE: 2.4330, MAE: 1.3357\n",
      "\n",
      "Rating Interval: [400, 450)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 1.1967, MAE: 0.8395\n",
      "Ridge (SGDRegressor) - MSE: 2.1220, MAE: 1.2285\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['soup'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                       columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "                       index=movies.index)\n",
    "\n",
    "print(f\"Tf-idf matrix shape: \", tfidf_matrix.shape)\n",
    "\n",
    "movie_id_to_index = {movie_id: i for i, movie_id in enumerate(movies['id'])}\n",
    "for i in range(1,5):\n",
    "    min_ratings = i * 100\n",
    "    max_ratings = min_ratings + 50\n",
    "\n",
    "    print(f\"\\nRating Interval: [{min_ratings}, {max_ratings})\")\n",
    "    \n",
    "    # Select all users within the rating count interval\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    eligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index\n",
    "\n",
    "    if len(eligible_users) == 0:\n",
    "        print(\"No users in this rating interval. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    lr_mse_list = []\n",
    "    lr_mae_list = []\n",
    "    ridge_mse_list = []\n",
    "    ridge_mae_list = []\n",
    "\n",
    "    for user_id in eligible_users:\n",
    "        user_ratings = ratings[ratings['userId'] == user_id]\n",
    "        user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n",
    "\n",
    "        user_movie_indices = [movie_id_to_index.get(movie_id) for movie_id in user_movies['id'].values]\n",
    "        user_movie_indices = [idx for idx in user_movie_indices if idx is not None]\n",
    "\n",
    "        if len(user_movie_indices) < 5:\n",
    "            continue\n",
    "\n",
    "        X = tfidf_matrix[user_movie_indices]\n",
    "        y = user_movies.loc[user_movies['id'].isin(\n",
    "            [movies['id'].iloc[idx] for idx in user_movie_indices]), 'rating'].values\n",
    "\n",
    "        if len(y) < 5:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Linear Regression\n",
    "            lr_model = LinearRegression()\n",
    "            lr_model.fit(X_train, y_train)\n",
    "            lr_pred_raw = lr_model.predict(X_test)\n",
    "            lr_pred = np.round(lr_pred_raw * 2) / 2\n",
    "            lr_pred = np.clip(lr_pred, 0.5, 5.0)\n",
    "\n",
    "            lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "            lr_mae = mean_absolute_error(y_test, lr_pred)\n",
    "            lr_mse_list.append(lr_mse)\n",
    "            lr_mae_list.append(lr_mae)\n",
    "\n",
    "            # Ridge (SGDRegressor)\n",
    "            sgd_model = SGDRegressor(penalty='l2', alpha=0.01, random_state=42)\n",
    "            sgd_model.fit(X_train, y_train)\n",
    "            ridge_pred_raw = sgd_model.predict(X_test)\n",
    "            ridge_pred = np.round(ridge_pred_raw * 2) / 2\n",
    "            ridge_pred = np.clip(ridge_pred, 0.5, 5.0)\n",
    "\n",
    "            ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "            ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "            ridge_mse_list.append(ridge_mse)\n",
    "            ridge_mae_list.append(ridge_mae)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    # Report averages for this interval\n",
    "    if lr_mse_list:\n",
    "        print(\"Average Model Evaluation:\")\n",
    "        print(f\"Linear Regression - MSE: {np.mean(lr_mse_list):.4f}, MAE: {np.mean(lr_mae_list):.4f}\")\n",
    "        print(f\"Ridge (SGDRegressor) - MSE: {np.mean(ridge_mse_list):.4f}, MAE: {np.mean(ridge_mae_list):.4f}\")\n",
    "    else:\n",
    "        print(\"Not enough valid users/data to compute average metrics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-12T01:44:42.665465Z",
     "iopub.status.idle": "2025-06-12T01:44:42.665744Z",
     "shell.execute_reply": "2025-06-12T01:44:42.665626Z",
     "shell.execute_reply.started": "2025-06-12T01:44:42.665614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "count = CountVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\n",
    "count_data = count.fit_transform(movies['description'])\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "trans_data = transformer.fit_transform(count_data)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T02:19:46.136162Z",
     "iopub.status.busy": "2025-06-12T02:19:46.135709Z",
     "iopub.status.idle": "2025-06-12T02:40:01.210624Z",
     "shell.execute_reply": "2025-06-12T02:40:01.208960Z",
     "shell.execute_reply.started": "2025-06-12T02:19:46.136136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie features shape: (5634, 26)\n",
      "\n",
      "Rating Interval: [50, 100)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 1.2721, MAE: 0.8363\n",
      "Ridge (SGDRegressor) - MSE: 1.5101, MAE: 0.9100\n",
      "\n",
      "Rating Interval: [100, 150)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.9765, MAE: 0.7339\n",
      "Ridge (SGDRegressor) - MSE: 1.0828, MAE: 0.7686\n",
      "\n",
      "Rating Interval: [150, 200)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.8878, MAE: 0.6998\n",
      "Ridge (SGDRegressor) - MSE: 0.9387, MAE: 0.7178\n",
      "\n",
      "Rating Interval: [200, 250)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.8441, MAE: 0.6817\n",
      "Ridge (SGDRegressor) - MSE: 0.8714, MAE: 0.6927\n",
      "\n",
      "Rating Interval: [250, 300)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.8085, MAE: 0.6691\n",
      "Ridge (SGDRegressor) - MSE: 0.8238, MAE: 0.6754\n",
      "\n",
      "Rating Interval: [300, 350)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.7814, MAE: 0.6576\n",
      "Ridge (SGDRegressor) - MSE: 0.7942, MAE: 0.6628\n",
      "\n",
      "Rating Interval: [350, 400)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.7387, MAE: 0.6403\n",
      "Ridge (SGDRegressor) - MSE: 0.7456, MAE: 0.6438\n",
      "\n",
      "Rating Interval: [400, 450)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.7934, MAE: 0.6648\n",
      "Ridge (SGDRegressor) - MSE: 0.7975, MAE: 0.6670\n",
      "\n",
      "Rating Interval: [450, 500)\n",
      "Average Model Evaluation:\n",
      "Linear Regression - MSE: 0.7477, MAE: 0.6436\n",
      "Ridge (SGDRegressor) - MSE: 0.7524, MAE: 0.6458\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [\n",
    "    'order_0', 'order_1', 'order_2', 'order_3', 'order_4',\n",
    "    'avg_rating', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n",
    "    'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n",
    "    'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n",
    "    'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "movies_features = modified_df[feature_columns].copy()\n",
    "movies_features.fillna(0, inplace=True) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_movie_features = scaler.fit_transform(movies_features)\n",
    "scaled_movie_features_df = pd.DataFrame(scaled_movie_features, columns=feature_columns, index=movies.index)\n",
    "\n",
    "\n",
    "print(f\"Movie features shape: {scaled_movie_features_df.shape}\")\n",
    "movie_id_to_index = {movie_id: i for i, movie_id in enumerate(movies['id'])}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    min_ratings = i * 50\n",
    "    max_ratings = min_ratings + 50\n",
    "\n",
    "    print(f\"\\nRating Interval: [{min_ratings}, {max_ratings})\")\n",
    "\n",
    "    # Select all users within the rating count interval\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    eligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index\n",
    "\n",
    "    if len(eligible_users) == 0:\n",
    "        print(\"No users in this rating interval. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    lr_mse_list = []\n",
    "    lr_mae_list = []\n",
    "    ridge_mse_list = []\n",
    "    ridge_mae_list = []\n",
    "\n",
    "    for user_id in eligible_users:\n",
    "        user_ratings = ratings[ratings['userId'] == user_id]\n",
    "        user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n",
    "\n",
    "        user_movie_indices = [movie_id_to_index.get(movie_id) for movie_id in user_movies['id'].values]\n",
    "        user_movie_indices = [idx for idx in user_movie_indices if idx is not None]\n",
    "\n",
    "        if len(user_movie_indices) < 5: # Need at least 5 data points for train/test split\n",
    "            continue\n",
    "\n",
    "        X = scaled_movie_features_df.iloc[user_movie_indices].values\n",
    "        y = user_movies.loc[user_movies['id'].isin(\n",
    "            [movies['id'].iloc[idx] for idx in user_movie_indices]), 'rating'].values\n",
    "\n",
    "        if len(y) < 5: \n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Linear Regression\n",
    "            lr_model = LinearRegression()\n",
    "            lr_model.fit(X_train, y_train)\n",
    "            lr_pred_raw = lr_model.predict(X_test)\n",
    "            lr_pred = np.round(lr_pred_raw * 2) / 2\n",
    "            lr_pred = np.clip(lr_pred, 0.5, 5.0)\n",
    "\n",
    "            lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "            lr_mae = mean_absolute_error(y_test, lr_pred)\n",
    "            lr_mse_list.append(lr_mse)\n",
    "            lr_mae_list.append(lr_mae)\n",
    "\n",
    "            # Ridge (SGDRegressor)\n",
    "            sgd_model = SGDRegressor(penalty='l2', alpha=0.01, random_state=42, max_iter=1000) # Added max_iter\n",
    "            sgd_model.fit(X_train, y_train)\n",
    "            ridge_pred_raw = sgd_model.predict(X_test)\n",
    "            ridge_pred = np.round(ridge_pred_raw * 2) / 2\n",
    "            ridge_pred = np.clip(ridge_pred, 0.5, 5.0)\n",
    "\n",
    "            ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "            ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "            ridge_mse_list.append(ridge_mse)\n",
    "            ridge_mae_list.append(ridge_mae)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    if lr_mse_list:\n",
    "        print(\"Average Model Evaluation:\")\n",
    "        print(f\"Linear Regression - MSE: {np.mean(lr_mse_list):.4f}, MAE: {np.mean(lr_mae_list):.4f}\")\n",
    "        print(f\"Ridge (SGDRegressor) - MSE: {np.mean(ridge_mse_list):.4f}, MAE: {np.mean(ridge_mae_list):.4f}\")\n",
    "    else:\n",
    "        print(\"Not enough valid users/data to compute average metrics.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3405,
     "sourceId": 6663,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 373875,
     "modelInstanceId": 352593,
     "sourceId": 432507,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
